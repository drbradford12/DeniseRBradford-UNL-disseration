<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>CHAPTER 4 Does Color Help?: Multidimensional Ensembles in Bland-Altman Plots: An Exploration | DATA SCIENCE, DASHBOARDS, AND THE WAY IT WORKS WITH STATISTICS</title>
  <meta name="description" content="CHAPTER 4 Does Color Help?: Multidimensional Ensembles in Bland-Altman Plots: An Exploration | DATA SCIENCE, DASHBOARDS, AND THE WAY IT WORKS WITH STATISTICS" />
  <meta name="generator" content="bookdown 0.33 and GitBook 2.6.7" />

  <meta property="og:title" content="CHAPTER 4 Does Color Help?: Multidimensional Ensembles in Bland-Altman Plots: An Exploration | DATA SCIENCE, DASHBOARDS, AND THE WAY IT WORKS WITH STATISTICS" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="CHAPTER 4 Does Color Help?: Multidimensional Ensembles in Bland-Altman Plots: An Exploration | DATA SCIENCE, DASHBOARDS, AND THE WAY IT WORKS WITH STATISTICS" />
  
  
  

<meta name="author" content="Denise Renee Bradford" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="math-sci.html"/>
<link rel="next" href="conclusion-1.html"/>
<style type="text/css">
p.abstract{
  text-align: center;
  font-weight: bold;
}
div.abstract{
  margin: auto;
  width: 90%;
}
</style>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#perceptual-and-cognitive-process-of-graph-perception"><i class="fa fa-check"></i><b>1.1</b> Perceptual and Cognitive Process of Graph Perception</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="introduction.html"><a href="introduction.html#visual-system"><i class="fa fa-check"></i><b>1.1.1</b> Visual System</a></li>
<li class="chapter" data-level="1.1.2" data-path="introduction.html"><a href="introduction.html#gestalt-principles"><i class="fa fa-check"></i><b>1.1.2</b> Gestalt Principles</a></li>
<li class="chapter" data-level="1.1.3" data-path="introduction.html"><a href="introduction.html#role-of-attention-and-f.i.t.-feature-integration-theory"><i class="fa fa-check"></i><b>1.1.3</b> Role of Attention and F.I.T. (Feature Integration Theory)</a></li>
<li class="chapter" data-level="1.1.4" data-path="introduction.html"><a href="introduction.html#top-down-vs.-bottom-up-construting-meaning"><i class="fa fa-check"></i><b>1.1.4</b> Top-Down vs. Bottom-Up (Construting Meaning)</a></li>
<li class="chapter" data-level="1.1.5" data-path="introduction.html"><a href="introduction.html#working-memory-why-cant-i-remember-someones-phone-number"><i class="fa fa-check"></i><b>1.1.5</b> Working Memory (Why can’t I remember someone’s phone number?)</a></li>
<li class="chapter" data-level="1.1.6" data-path="introduction.html"><a href="introduction.html#role-of-expertise"><i class="fa fa-check"></i><b>1.1.6</b> Role of Expertise</a></li>
<li class="chapter" data-level="1.1.7" data-path="introduction.html"><a href="introduction.html#engagement-with-the-data"><i class="fa fa-check"></i><b>1.1.7</b> Engagement with the data</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#data-considerations"><i class="fa fa-check"></i><b>1.2</b> Data Considerations</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#audience-data-interactions"><i class="fa fa-check"></i><b>1.3</b> Audience-Data Interactions</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="introduction.html"><a href="introduction.html#human-computer-interaction-hci"><i class="fa fa-check"></i><b>1.3.1</b> Human-Computer Interaction (HCI)</a></li>
<li class="chapter" data-level="1.3.2" data-path="introduction.html"><a href="introduction.html#user-experience-ux"><i class="fa fa-check"></i><b>1.3.2</b> User Experience (UX)</a></li>
<li class="chapter" data-level="1.3.3" data-path="introduction.html"><a href="introduction.html#ux-and-cognitive-load"><i class="fa fa-check"></i><b>1.3.3</b> UX and Cognitive Load</a></li>
<li class="chapter" data-level="1.3.4" data-path="introduction.html"><a href="introduction.html#infomation-search-enviroment"><i class="fa fa-check"></i><b>1.3.4</b> Infomation Search Enviroment</a></li>
<li class="chapter" data-level="1.3.5" data-path="introduction.html"><a href="introduction.html#chart-coordinationviusal-linking"><i class="fa fa-check"></i><b>1.3.5</b> Chart Coordination/Viusal Linking</a></li>
<li class="chapter" data-level="1.3.6" data-path="introduction.html"><a href="introduction.html#testing-static-graphics"><i class="fa fa-check"></i><b>1.3.6</b> Testing static graphics</a></li>
<li class="chapter" data-level="1.3.7" data-path="introduction.html"><a href="introduction.html#testing-interactive-graphics"><i class="fa fa-check"></i><b>1.3.7</b> Testing interactive graphics</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#dashboard-design"><i class="fa fa-check"></i><b>1.4</b> Dashboard Design</a></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#dissertation-map"><i class="fa fa-check"></i><b>1.5</b> Dissertation Map</a></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#conclusion"><i class="fa fa-check"></i><b>1.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="rmd-basics.html"><a href="rmd-basics.html"><i class="fa fa-check"></i><b>2</b> Chapter Paper on Rural Shrink Smart Manuscript submitted to Journal of Data Science Special Issue</a>
<ul>
<li class="chapter" data-level="2.1" data-path="rmd-basics.html"><a href="rmd-basics.html#abstract"><i class="fa fa-check"></i><b>2.1</b> Abstract</a></li>
<li class="chapter" data-level="2.2" data-path="rmd-basics.html"><a href="rmd-basics.html#introduction-1"><i class="fa fa-check"></i><b>2.2</b> Introduction</a></li>
<li class="chapter" data-level="2.3" data-path="rmd-basics.html"><a href="rmd-basics.html#data-description"><i class="fa fa-check"></i><b>2.3</b> Data Description</a></li>
<li class="chapter" data-level="2.4" data-path="rmd-basics.html"><a href="rmd-basics.html#dashboard-design-considerations"><i class="fa fa-check"></i><b>2.4</b> Dashboard Design Considerations</a></li>
<li class="chapter" data-level="2.5" data-path="rmd-basics.html"><a href="rmd-basics.html#guiding-design-principles"><i class="fa fa-check"></i><b>2.5</b> Guiding Design Principles</a></li>
<li class="chapter" data-level="2.6" data-path="rmd-basics.html"><a href="rmd-basics.html#dashboard-design-process"><i class="fa fa-check"></i><b>2.6</b> Dashboard Design Process</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="rmd-basics.html"><a href="rmd-basics.html#dashboard-components"><i class="fa fa-check"></i><b>2.6.1</b> Dashboard Components</a></li>
<li class="chapter" data-level="2.6.2" data-path="rmd-basics.html"><a href="rmd-basics.html#initial-draft"><i class="fa fa-check"></i><b>2.6.2</b> Initial Draft</a></li>
<li class="chapter" data-level="2.6.3" data-path="rmd-basics.html"><a href="rmd-basics.html#redesign"><i class="fa fa-check"></i><b>2.6.3</b> Redesign</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="rmd-basics.html"><a href="rmd-basics.html#discussion"><i class="fa fa-check"></i><b>2.7</b> Discussion</a></li>
<li class="chapter" data-level="2.8" data-path="rmd-basics.html"><a href="rmd-basics.html#future-work"><i class="fa fa-check"></i><b>2.8</b> Future Work</a></li>
<li class="chapter" data-level="2.9" data-path="rmd-basics.html"><a href="rmd-basics.html#conclusions"><i class="fa fa-check"></i><b>2.9</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="math-sci.html"><a href="math-sci.html"><i class="fa fa-check"></i><b>3</b> Dashboard Poetry</a>
<ul>
<li class="chapter" data-level="3.1" data-path="math-sci.html"><a href="math-sci.html#introduction-2"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="math-sci.html"><a href="math-sci.html#dashbaord-construction"><i class="fa fa-check"></i><b>3.2</b> Dashbaord Construction</a></li>
<li class="chapter" data-level="3.3" data-path="math-sci.html"><a href="math-sci.html#cognitive-principles"><i class="fa fa-check"></i><b>3.3</b> Cognitive Principles</a></li>
<li class="chapter" data-level="3.4" data-path="math-sci.html"><a href="math-sci.html#ensemble-perception"><i class="fa fa-check"></i><b>3.4</b> Ensemble Perception</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="math-sci.html"><a href="math-sci.html#ensemble-visualization"><i class="fa fa-check"></i><b>3.4.1</b> Ensemble Visualization</a></li>
<li class="chapter" data-level="3.4.2" data-path="math-sci.html"><a href="math-sci.html#multidimensional-ensembles"><i class="fa fa-check"></i><b>3.4.2</b> Multidimensional Ensembles</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ref-labels.html"><a href="ref-labels.html"><i class="fa fa-check"></i><b>4</b> Does Color Help?: Multidimensional Ensembles in Bland-Altman Plots: An Exploration</a>
<ul>
<li class="chapter" data-level="4.1" data-path="ref-labels.html"><a href="ref-labels.html#introduction-3"><i class="fa fa-check"></i><b>4.1</b> Introduction:</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="ref-labels.html"><a href="ref-labels.html#ensemble-perception-1"><i class="fa fa-check"></i><b>4.1.1</b> Ensemble Perception</a></li>
<li class="chapter" data-level="4.1.2" data-path="ref-labels.html"><a href="ref-labels.html#multidimensional-ensembles-1"><i class="fa fa-check"></i><b>4.1.2</b> Multidimensional Ensembles</a></li>
<li class="chapter" data-level="4.1.3" data-path="ref-labels.html"><a href="ref-labels.html#bland-altman-plots"><i class="fa fa-check"></i><b>4.1.3</b> Bland-Altman Plots</a></li>
<li class="chapter" data-level="4.1.4" data-path="ref-labels.html"><a href="ref-labels.html#the-intersection-of-multidimensional-ensembles-and-bland-altman-plots"><i class="fa fa-check"></i><b>4.1.4</b> The intersection of Multidimensional Ensembles and Bland-Altman Plots</a></li>
<li class="chapter" data-level="4.1.5" data-path="ref-labels.html"><a href="ref-labels.html#gaps-in-research"><i class="fa fa-check"></i><b>4.1.5</b> Gaps in Research</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="ref-labels.html"><a href="ref-labels.html#methods"><i class="fa fa-check"></i><b>4.2</b> Methods:</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="ref-labels.html"><a href="ref-labels.html#design-of-the-user-studies"><i class="fa fa-check"></i><b>4.2.1</b> Design of the User Studies</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="ref-labels.html"><a href="ref-labels.html#discussion-1"><i class="fa fa-check"></i><b>4.3</b> Discussion:</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="conclusion-1.html"><a href="conclusion-1.html"><i class="fa fa-check"></i>Conclusion</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="the-first-appendix.html"><a href="the-first-appendix.html"><i class="fa fa-check"></i><b>A</b> The First Appendix</a></li>
<li class="chapter" data-level="B" data-path="the-second-appendix-for-fun.html"><a href="the-second-appendix-for-fun.html"><i class="fa fa-check"></i><b>B</b> The Second Appendix, for Fun</a></li>
<li class="chapter" data-level="" data-path="colophon.html"><a href="colophon.html"><i class="fa fa-check"></i>Colophon</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">DATA SCIENCE, DASHBOARDS, AND THE WAY IT WORKS WITH STATISTICS</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ref-labels" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">CHAPTER 4</span> Does Color Help?: Multidimensional Ensembles in Bland-Altman Plots: An Exploration<a href="ref-labels.html#ref-labels" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="introduction-3" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Introduction:<a href="ref-labels.html#introduction-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>“How can multidimensional ensembles be effectively incorporated into Bland-Altman plots to enhance the accuracy and comprehensibility of assessing agreement between multiple measurement techniques?”
This research question explores the theoretical and practical implications of incorporating ensemble perception and multidimensional data into Bland-Altman plots, traditionally used for comparing two measurement methods.
By doing so, the research seeks to advance the utility and interpretability of these plots in complex, real-world scenarios where multiple dimensions are often at play.
The interpretation of Bland-Altman plots is conventionally one-dimensional, focusing primarily on the mean difference and limits of agreement <span class="citation">(Bland &amp; Altman, 1986)</span>.
However, in real-world applications, the measurements under consideration often contain multiple dimensions that could contribute to interpreting the agreement or disagreement between two techniques <span class="citation">(Chong &amp; Treisman, 2003)</span>.
A detailed counterexample of the utility and interpretability of Bland-Altman plots in complex, real-world scenarios can be seen where two techniques are being compared for measuring blood pressure.
The Bland-Altman plot may show good agreement between the mean difference and the limits of agreement, suggesting high concordance.
However, when considering additional dimensions such as accuracy and precision in different subgroups (e.g., age, gender), it could reveal significant discrepancies and limitations in the interpretation of Ensemble coding, a perceptual mechanism that provides a statistical summary of a visual scene, offers a promising solution by facilitating the rapid extraction of variability information <span class="citation">(Alvarez, 2011)</span>.
The theory of ensemble perception offers a framework for understanding how these multiple dimensions could be processed simultaneously <span class="citation">(J. Haberman et al., 2015)</span> and <span class="citation">(Whitney et al., 2014)</span>.</p>
<div id="ensemble-perception-1" class="section level3 hasAnchor" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> Ensemble Perception<a href="ref-labels.html#ensemble-perception-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Ensemble perception is the cognitive ability to quickly derive summary statistics from sets of similar items <span class="citation">(Chong &amp; Treisman, 2003)</span>.
This component of visual cognition enables the visual system to summarize and describe collections of comparable objects or features effectively.
This capability is often activated at a glance and is crucial for making sense of complex visual scenes.</p>
<p>David Whitney’s fundamental review outlines the core principles of ensemble perception, emphasizing the extraction of summary statistical information from groups of similar objects <span class="citation">(Whitney et al., 2014)</span> and <span class="citation">(Dakin &amp; Watt, 1997)</span>.<br />
<span class="citation">(J. Haberman et al., 2015)</span> further discussed that individual differences exist in ensemble perception capabilities, indicating the presence of multiple, independent levels of ensemble representation.<br />
Recent studies have expanded on these principles.<br />
Khayat et al.’s work explores how ensemble perception can create a unified perception from groups of similar objects and also delves into the implicit perception and memory of set statistics <span class="citation">(Khayat et al., 2023)</span> and <span class="citation">(Khayat et al., 2021)</span>.<br />
The study “Perceptual History Biases in Serial Ensemble Representation” by Khayat et al. focuses on ensemble perception, explicitly examining how past visual experiences influence the perception of current visual ensembles.<br />
The study investigates the serial dependence of ensemble perception when each ensemble set is presented simultaneously but spatially distributed over the screen.<br />
This suggests that the objects and our prior experiences with similar ensembles impact how we perceive groups of similar objects <span class="citation">(Khayat et al., 2023)</span>.
This adds a layer of complexity to the understanding of ensemble perception, which is generally considered the visual system’s ability to summarize groups of similar objects into a unified perception efficiently.<br />
The study “Perceiving ensemble statistics of novel image sets” by Khayat et al. focuses on how the human visual system perceives summary statistics of sets of stimulus elements.<br />
The study is particularly interested in how we perceive novel image sets and hypothesizes that our capacity to summarize statistical data from these sets affects how well we can comprehend and interpret new visual information <span class="citation">(Khayat et al., 2021)</span>.
This research contributes to the broader field of ensemble perception, which explores how the visual system can efficiently represent groups of similar objects as a unified perception.<br />
The study implies that not only can the visual system quickly grasp the “gist” or essence of familiar visual ensembles, but it can also do so for novel sets of images.<br />
This ability to quickly summarize statistical information from new visual stimuli could be a fundamental feature of human perception <span class="citation">(Khayat &amp; Hochstein, 2018)</span>.<br />
Other research has investigated the role of ensemble perception in both high- and low-level visual information, such as emotion and brightness, and how it can even operate when scene information is incomplete <span class="citation">(Chakrabarty &amp; Wada, 2020)</span> and <span class="citation">(J. M. Haberman &amp; Ulrich, 2019)</span>.</p>
<p>Furthermore, ensemble perception is not just a specialized function but a pervasive aspect of visual perception.<br />
It has been discussed holistically to engage a general audience and has been shown to condense redundant information into summary statistical representations <span class="citation">(Corbett et al., 2023)</span> and <span class="citation">(Whitney &amp; Manassi, 2022)</span>.<br />
Lastly, stable ensemble representations have been found to facilitate visual search, even when they are not predictive of a target location <span class="citation">(Utochkin et al., 2023)</span>.
The study focuses on a coding model that emphasizes the crucial role of the “pooling layer” in ensemble perception.<br />
Ensemble perception refers to the ability of the visual system to summarize information from a group of similar objects.
The “pooling layer” in the model likely serves as a computational mechanism for aggregating or summarizing this information, potentially providing insights into how the brain processes complex visual scenes.
The study aims to provide a more structured understanding of ensemble perception by introducing a model highlighting the importance of a specific computational layer, known as the “pooling layer,” in summarizing visual information.</p>
</div>
<div id="multidimensional-ensembles-1" class="section level3 hasAnchor" number="4.1.2">
<h3><span class="header-section-number">4.1.2</span> Multidimensional Ensembles<a href="ref-labels.html#multidimensional-ensembles-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Initial research on ensemble perception primarily focused on one-dimensional ensembles, where summary statistics are extracted from a single feature or dimension <span class="citation">(J. Haberman et al., 2015)</span>.
For example, in a study on facial expression perception, participants were presented with an ensemble of faces displaying different emotions.
In this case, the pooling layer would analyze the overall emotional expression of the ensemble, summarizing the various individual facial expressions into one general emotion perception.
This model allows researchers to understand how humans perceive and interpret complex emotional expressions more systematically.
However, as <span class="citation">(Maule &amp; Franklin, 2015)</span> notes, real-world scenes often consist of complex, multidimensional attributes, and research has gradually shifted towards understanding how the human visual system processes these more intricate ensembles.
Research on multidimensional ensembles has explored how people simultaneously perceive summary statistics across multiple attributes, such as size and color.</p>
<p><span class="citation">(Dakin &amp; Watt, 1997)</span> were among the first to explore how orientation statistics are computed from visual textures, extending the concept of ensemble perception into a multidimensional setting.
<span class="citation">(J. Haberman et al., 2015)</span> expanded this research by showing that individual differences exist in ensemble perception capabilities, suggesting multiple, independent levels of ensemble representation exist.
The existing literature on multidimensional ensembles in visual information covers various topics, from neuroscience to data visualization.<br />
For instance, studies have explored the role of neuronal ensembles in controlling visually guided behavior and their influence on visual working memory <span class="citation">(Carrillo-Reid et al., 2019)</span>.
Research has also delved into the use of aggregated plots for multidimensional visual analysis, although these don’t explicitly mention ensembles <span class="citation">(Fofonov &amp; Linsen, 2018)</span>.<br />
Fast ensemble representations have been investigated to understand high-level perceptual impressions based on visual information <span class="citation">(Leib et al., 2016)</span>.</p>
<p>Additionally, the aesthetic complexity of visual information has been quantified using information theory, offering a potential framework for ensemble-based representations <span class="citation">(Karjus et al., 2023)</span>.
But a detailed example of why you shouldn’t use aggregated plots for multidimensional visual analysis is when the individual data points in the ensemble show significant differences. Data aggregation may obscure important patterns in such scenarios and lead to misleading interpretations.
Further, ensembles may fail to capture the fine-grained details and nuances present in the individual plots, compromising the overall accuracy and precision of the analysis.
The long-term stability of neuronal ensembles in the visual cortex has been studied, shedding light on their potential role in visual perception <span class="citation">(Pérez-Ortega et al., 2021)</span>.
Ensemble visualization techniques, particularly in computer simulations, have also been reviewed <span class="citation">(Afzal et al., 2019)</span>.
Lastly, the structure of neural networks has been shown to affect working memory, which could have implications for visual ensembles <span class="citation">(Leavitt et al., 2017)</span>.</p>
</div>
<div id="bland-altman-plots" class="section level3 hasAnchor" number="4.1.3">
<h3><span class="header-section-number">4.1.3</span> Bland-Altman Plots<a href="ref-labels.html#bland-altman-plots" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The study of multidimensional ensembles has seen applications in the field of data visualization.
<span class="citation">(Szafir, 2017)</span> showed that understanding color differences could improve the design of visualizations that require the viewer to integrate multiple pieces of information.
This work suggested that effective visualization tools could be designed by leveraging the human ability to process multidimensional ensembles rapidly.</p>
<p>Bland-Altman Plots are widely used in clinical research for assessing the agreement between two measurement techniques by plotting the differences against the means <span class="citation">(Bland &amp; Altman, 1986)</span>.
They offer a straightforward representation of data, making them a popular choice for visualizing measurement bias.
However, the plots are conventionally one-dimensional, primarily focusing on mean differences and limits of agreement.</p>
</div>
<div id="the-intersection-of-multidimensional-ensembles-and-bland-altman-plots" class="section level3 hasAnchor" number="4.1.4">
<h3><span class="header-section-number">4.1.4</span> The intersection of Multidimensional Ensembles and Bland-Altman Plots<a href="ref-labels.html#the-intersection-of-multidimensional-ensembles-and-bland-altman-plots" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The application of multidimensional ensembles in Bland-Altman Plots could potentially offer a more nuanced understanding of data.
For example, integrating color coding to indicate standard deviation and shape variations to indicate skewness could offer additional layers of information in a single plot <span class="citation">(Szafir, 2017)</span>.
Such an approach could leverage our innate abilities in ensemble perception to offer a more comprehensive assessment of agreement between multiple sets of measurement techniques <span class="citation">(Szafir, Haroz, Gleicher, &amp; Franconeri, 2016)</span>.</p>
</div>
<div id="gaps-in-research" class="section level3 hasAnchor" number="4.1.5">
<h3><span class="header-section-number">4.1.5</span> Gaps in Research<a href="ref-labels.html#gaps-in-research" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>While the fields of ensemble perception and data visualization have seen significant growth, there is a lack of research focusing on the application of ensemble perception, particularly multidimensional ensembles, in Bland-Altman Plots.
This gap points to the need for empirical studies designed to validate theoretical frameworks and to assess the practical utility of incorporating multidimensional ensembles into Bland-Altman Plots.</p>
</div>
</div>
<div id="methods" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Methods:<a href="ref-labels.html#methods" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Ensemble perception involves the rapid and often unconscious extraction of summary statistics from a set of similar items <span class="citation">(Chong &amp; Treisman, 2003)</span>, <span class="citation">(Whitney et al., 2014)</span>.
In the context of multidimensional ensembles, this would refer to the simultaneous extraction of various features such as mean, variance, and other statistical attributes across multiple dimensions <span class="citation">(Maule &amp; Franklin, 2015)</span>, <span class="citation">(J. Haberman et al., 2015)</span>.
Understanding this concept will provide a unique way to interpret Bland-Altman plots that contain data from multiple dimensions.</p>
<p>Traditionally, Bland-Altman plots present the difference between two sets of measurements against their mean, providing a graphical representation of agreement or bias.
However, this one-dimensional representation might not capture the full complexity of real-world data, where measurements can often be multidimensional <span class="citation">(Dakin &amp; Watt, 1997)</span>.
Given the human brain’s ability to rapidly process multidimensional ensemble statistics <span class="citation">(J. Haberman et al., 2015)</span>, incorporating this aspect into Bland-Altman plots might yield a more nuanced interpretation <span class="citation">(Bauer, 2009)</span>, <span class="citation">(Szafir et al., 2016)</span>.</p>
<p>One way to incorporate multidimensionality into Bland-Altman plots is by adding layers that represent different statistical attributes.
For example, varying shades of color could indicate the standard deviation within each plotted point, and shape variations could indicate another dimension such as skewness or kurtosis <span class="citation">(Szafir, 2017)</span>.
This model would require human observers to simultaneously extract multiple summary statistics, leveraging the brain’s capabilities in ensemble perception <span class="citation">(Chong &amp; Treisman, 2003)</span>.</p>
<p>In this proposed study, we utilize color coding to represent varying levels of variability in Bland-Altman plots.
To ensure the universal interpretability of the plots <span class="citation">(Ware, 2012)</span>, the color palette will be selected with care, taking into account potential issues such as color blindness.</p>
<p>For this study, two Bland-Altman plots will be generated.
A traditional plot without color-coding and a plot using the color-coding technique we propose.
Both plots will be presented to a group of participants that includes both experts and non-experts in data interpretation and statistics.
The participants will be required to interpret the plots and complete a questionnaire to assess their comprehension and speed of interpretation.</p>
<p>For a layer of interactivity in our study, we will generate interactive Bland-Altman plots incorporating ensemble coding of variability through color gradations.
Interactivity will be implemented via D3, providing detailed information about each data point when hovered over, as well as zoom features allowing users to zero in on areas of interest.</p>
<div id="design-of-the-user-studies" class="section level3 hasAnchor" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Design of the User Studies<a href="ref-labels.html#design-of-the-user-studies" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>User studies will be designed to assess the effectiveness of the interactive Bland-Altman plots in conveying information about the variability of data points.
The studies will consist of two parts:</p>
<p><strong>Task-based Evaluation:</strong> Participants will be given a set of tasks to complete using both the interactive color-coded Bland-Altman plot and a traditional static Bland-Altman plot.
Tasks will involve identifying specific data points, interpreting data variability, and answering questions about the overall data trend.
Metrics such as task completion time, success rate, and error rate will be recorded <span class="citation">(Rubin &amp; Chisnell, 2008)</span>.</p>
<p><strong>Subjective Evaluation:</strong> After completing the tasks, participants will be asked to fill out a questionnaire assessing their user experience.
The questionnaire will include items related to the perceived ease of use, satisfaction, and preference between the traditional and interactive color-coded Bland-Altman plots.</p>
</div>
</div>
<div id="discussion-1" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Discussion:<a href="ref-labels.html#discussion-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We anticipate that the application of ensemble coding for variability will aid in the comprehension of Bland-Altman plots.
Based on ensemble coding principles, the color-coded plot should enable faster and more accurate interpretation of data variability <span class="citation">(J. Haberman &amp; Whitney, 2012)</span>.
This method has the potential to enhance the interpretability and utility of these graphs, making them accessible to a broader audience and facilitating more efficient data communication.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="math-sci.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="conclusion-1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/drbradford12/DeniseRBradford-UNL-disseration/edit/master/04-chap3.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/drbradford12/DeniseRBradford-UNL-disseration/blob/master/04-chap3.Rmd",
"text": null
},
"download": [["thesis.pdf", "PDF"]],
"search": {
"engine": "lunr",
"options": null
},
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"info": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
